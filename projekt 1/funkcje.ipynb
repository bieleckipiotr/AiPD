{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parametryzacja wymagana do przeprowadzenia odpowiednich kalkulacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_size = 512\n",
    "window_size = 128\n",
    "directory = \"./data/znormalizowane/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ekstrakcja cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_frames(samples, frame_size):\n",
    "    frames = []\n",
    "    for i in range(0, len(samples), frame_size):\n",
    "        frame = samples[i:i+frame_size]\n",
    "        frame = np.asarray(frame, dtype = np.float32)\n",
    "        frames.append(frame)\n",
    "    return frames\n",
    "\n",
    "\n",
    "def calculate_zcr(frames):\n",
    "    zcrs = [np.sum(librosa.zero_crossings(frame)) for frame in frames]\n",
    "    return zcrs\n",
    "\n",
    "def calculate_f0(samples):\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(samples, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'), frame_length=frame_size, win_length=window_size)\n",
    "    times = librosa.times_like(f0)\n",
    "    return(times, f0, voiced_flag)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_rms(samples):\n",
    "    rms = librosa.feature.rms(y = samples, frame_length=frame_size, hop_length = frame_size)\n",
    "    return rms\n",
    "\n",
    "\n",
    "def calculate_ste(volumes):\n",
    "    return volumes**2\n",
    "\n",
    "\n",
    "def calculate_sr(volume, zcr):\n",
    "    return(1*(volume < 0.02) * (np.array(zcr) < 50))\n",
    "\n",
    "\n",
    "def calculate_features(samples, frame_size):\n",
    "    frames = divide_into_frames(samples, frame_size)\n",
    "\n",
    "    volumes = calculate_rms(samples)\n",
    "    stes = calculate_ste(volumes)\n",
    "    zcrs = calculate_zcr(frames)\n",
    "    times, f0, voiced_flag = calculate_f0(samples)\n",
    "    sr = calculate_sr(volumes, zcrs)\n",
    "\n",
    "    VSTD = np.std(volumes) / np.max(volumes)\n",
    "    VDR = ( np.max(volumes) - np.min(volumes) ) / np.max(volumes)\n",
    "    LSTER = []\n",
    "    for i in range(0, len(samples), 22050):\n",
    "        if i+22050 > len(samples):\n",
    "            mean = np.mean(stes[len(samples)-22050:len(samples)])\n",
    "        else:\n",
    "            mean = np.mean(stes[i:i+22050])\n",
    "        if len(samples) < 22050:\n",
    "            mean = np.mean(samples)\n",
    "        LSTER.append( 1/2 * np.mean(np.sum(((1/2 * mean - stes[i:i+22050]) > 0)*1 + 1)) )\n",
    "    LSTER = np.mean(LSTER)\n",
    "    \n",
    "    energy_segments = []\n",
    "    for frame in frames:\n",
    "        for i in range(0, len(frame), window_size):\n",
    "            s = frame[i: i+window_size]\n",
    "            energy_segments.append(np.mean(s**2))\n",
    "    energy_segments /= np.sum(energy_segments)\n",
    "    entropy = -np.sum(energy_segments*np.log2(energy_segments))\n",
    "    HZCRR = np.mean(np.sum( ((zcrs - 3/2 * np.mean(zcrs)) > 0)*1 + 1))/2\n",
    "    \n",
    "    \n",
    "    features = {\n",
    "        \"volume\" : np.array(volumes).reshape(-1,1),\n",
    "        \"short time energy\" : np.array(stes).reshape(-1,1),\n",
    "        \"zero crossing rate\" : np.array(zcrs).reshape(-1,1),\n",
    "        \"fundamental frequency\" : np.array(f0).reshape(-1,1),\n",
    "        \"voiced flag\" : np.array(voiced_flag).reshape(-1,1),\n",
    "        \"silent ratio\" : np.array(sr).reshape(-1,1),\n",
    "    }\n",
    "    values = {\n",
    "        \"VSTD\" : VSTD,\n",
    "        \"VDR\" : VDR,\n",
    "        \"ZSTD\" : np.std(zcrs),\n",
    "        \"HZCRR\" : HZCRR,\n",
    "        \"entropy\" : entropy,\n",
    "        \"Low Ste Ratio\" : LSTER\n",
    "        }\n",
    "    return features, values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wykresy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_volume_time(duration, volumes):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.plot(np.linspace(0, duration, len(volumes)), volumes)\n",
    "    plt.title('Volume over time')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Volume')\n",
    "\n",
    "\n",
    "def plot_features(samples, features, duration, filename):\n",
    "    n = len(features)\n",
    "    fig, ax = plt.subplots(n-2, 1)\n",
    "    fig.set_size_inches(30, 4*n-8)\n",
    "\n",
    "    sr = features.pop(\"silent ratio\")\n",
    "    f0 = features.pop(\"fundamental frequency\")\n",
    "    voiced = features.pop(\"voiced flag\")\n",
    "\n",
    "\n",
    "    times = np.linspace(0, duration, len(samples))\n",
    "    ax[0].plot(times, samples, linewidth = 1/2)\n",
    "    ax[0].set_title('Amplitude over time')\n",
    "    ax[0].set_ylabel('Amplitude')\n",
    "    for j in np.where(voiced)[0]:\n",
    "        ax[0].axvspan(times[np.int64(j*len(samples)/len(voiced))], times[np.int64((j+1)*len(samples)/len(voiced))], color='green', alpha=0.3)\n",
    "\n",
    "    for i, feature in enumerate(list(features.items())[:-1]):\n",
    "        i = i+1\n",
    "        name, data = feature\n",
    "        times = np.linspace(0, duration, len(data))\n",
    "        ax[i].plot(times, data, linewidth = 1)\n",
    "        ax[i].set_title(name)\n",
    "        ax[i].set_ylabel(name)\n",
    "        for j in range(len(sr)-1):\n",
    "            if sr[j] == 1:\n",
    "                ax[i].axvspan(times[np.int64(j*len(data)/len(sr))], times[np.int64((j+1)*len(data)/len(sr))], color='red', alpha=0.5)\n",
    "    plt.xlabel('Time [seconds]')\n",
    "\n",
    "    times = np.linspace(0, duration, len(f0))\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(samples)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax[-1]) \n",
    "    ax[-1].set(title='pYIN fundamental frequency estimation')\n",
    "    fig.colorbar(img, ax=ax[-1], format=\"%+2.f dB\")\n",
    "    ax[-1].plot(times, f0, label='f0', color='cyan', linewidth=3)\n",
    "    fig.legend().set_visible(False)\n",
    "    # ax[-1].legend(loc='upper right', fontsize=\"4\", borderpad = 0, borderaxespad = 0)\n",
    "    IPython.display.display(Audio(filename, rate = sample_rate, autoplay=True))\n",
    "\n",
    "def plot_features_df(row):\n",
    "    features = {\n",
    "        \"volume\" :row.volume,\n",
    "        \"short time energy\" : row['short time energy']\t,\n",
    "        \"zero crossing rate\" : row['zero crossing rate'],\n",
    "        \"fundamental frequency\" : row['fundamental frequency'],\n",
    "        \"voiced flag\" : row['voiced flag'],\n",
    "        \"silent ratio\" : row['silent ratio'],\n",
    "    }\n",
    "    n = len(features)\n",
    "    fig, ax = plt.subplots(n-2, 1)\n",
    "    fig.set_size_inches(30, 4*n-8)\n",
    "\n",
    "    sr = features.pop(\"silent ratio\")\n",
    "    f0 = features.pop(\"fundamental frequency\")\n",
    "    voiced = features.pop(\"voiced flag\")\n",
    "\n",
    "\n",
    "    times = np.linspace(0, row.duration, len(row.samples))\n",
    "    ax[0].plot(times, row.samples, linewidth = 1/2)\n",
    "    ax[0].set_title('Amplitude over time')\n",
    "    ax[0].set_ylabel('Amplitude')\n",
    "    for j in np.where(voiced)[0]:\n",
    "        ax[0].axvspan(times[np.int64((j-1)*len(row.samples)/len(voiced))], times[np.int64((j)*len(row.samples)/len(voiced))], color='green', alpha=0.3)\n",
    "\n",
    "    for i, feature in enumerate(list(features.items())[:-1]):\n",
    "        i = i+1\n",
    "        name, data = feature\n",
    "        times = np.linspace(0, row.duration, len(data))\n",
    "        ax[i].plot(times, data, linewidth = 1)\n",
    "        ax[i].set_title(name)\n",
    "        ax[i].set_ylabel(name)\n",
    "        for j in range(len(sr)-1):\n",
    "            if sr[j] == [1]:\n",
    "                ax[i].axvspan(times[np.int64(j*len(data)/len(sr))], times[np.int64((j+1)*len(data)/len(sr))], color='red', alpha=0.5)\n",
    "    plt.xlabel('Time [seconds]')\n",
    "\n",
    "    times = np.linspace(0, row.duration, len(f0))\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(np.array(row.samples))), ref=np.max)\n",
    "    img = librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax[-1]) \n",
    "    ax[-1].set(title='pYIN fundamental frequency estimation')\n",
    "    # fig.colorbar(img, ax=ax[-1], format=\"%+2.f dB\")\n",
    "    ax[-1].plot(times, f0, label='f0', color='cyan', linewidth=3)\n",
    "    plt.legend('' , frameon=False)\n",
    "    print(f\"Values for the whole clip:\\n\\t name = {row['filename'].split('/')[-1]} \\n\\t duration = {row.duration}\\n\\t Volume Standard Deviation = {row.VSTD}\\n\\t\tVolume dynamic range = {row.VDR}\\n\\t standard deviation of ZCR = {row.ZSTD}\t\\n\\t High zero crossing rate = {row.HZCRR} \\n\\t entropy = {row.entropy} \\n\\t Low Ste Ratio = {row['Low Ste Ratio']}\")\n",
    "    # ax[-1].legend(loc='upper right', fontsize=\"4\", borderpad = 0, borderaxespad = 0)\n",
    "    IPython.display.display(Audio(row.filename, rate = row.sample_rate, autoplay=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wczytanie wszystkich danych do ramki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./data/znormalizowane/\"\n",
    "list_features = []\n",
    "list_values = []\n",
    "for f in os.listdir(directory):\n",
    "    filename = directory+f\n",
    "    samples, sample_rate = librosa.load(filename)\n",
    "    duration = len(samples) / sample_rate\n",
    "    features, values = calculate_features(samples, frame_size)\n",
    "    features['samples'] = samples\n",
    "    features['filename'] = filename\n",
    "    features['duration'] = duration\n",
    "    features['sample_rate'] = sample_rate\n",
    "    values['filename'] = filename\n",
    "    list_features.append(features)\n",
    "    list_values.append(values)\n",
    "list_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(list_features)\n",
    "df2 = pd.DataFrame(list_values)\n",
    "df = pd.concat([df1.set_index(\"filename\"), df2.set_index('filename')], axis = 1, join = 'inner').reset_index(drop=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zapis danych do csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"./data/output/processed_male.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### muzyka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./data/muzyka/znormalizowane/\"\n",
    "list_features = []\n",
    "list_values = []\n",
    "for f in os.listdir(directory):\n",
    "    filename = directory+f\n",
    "    samples, sample_rate = librosa.load(filename, mono = True)\n",
    "    duration = len(samples) / sample_rate\n",
    "    features, values = calculate_features(samples, frame_size)\n",
    "    features['samples'] = samples\n",
    "    features['filename'] = filename\n",
    "    features['duration'] = duration\n",
    "    features['sample_rate'] = sample_rate\n",
    "    values['filename'] = filename\n",
    "    list_features.append(features)\n",
    "    list_values.append(values)\n",
    "list_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(list_features)\n",
    "df2 = pd.DataFrame(list_values)\n",
    "df_music = pd.concat([df1.set_index(\"filename\"), df2.set_index('filename')], axis = 1, join = 'inner').reset_index(drop=False)\n",
    "df_music.to_json(\"./data/output/processed_music.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "głos kobiecy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./data/głos koleżanki/znormalizowane/\"\n",
    "list_features = []\n",
    "list_values = []\n",
    "for f in os.listdir(directory):\n",
    "    filename = directory+f\n",
    "    samples, sample_rate = librosa.load(filename, mono = True)\n",
    "    duration = len(samples) / sample_rate\n",
    "    features, values = calculate_features(samples, frame_size)\n",
    "    features['samples'] = samples\n",
    "    features['filename'] = filename\n",
    "    features['duration'] = duration\n",
    "    features['sample_rate'] = sample_rate\n",
    "    values['filename'] = filename\n",
    "    list_features.append(features)\n",
    "    list_values.append(values)\n",
    "list_features\n",
    "df1 = pd.DataFrame(list_features)\n",
    "df2 = pd.DataFrame(list_values)\n",
    "df_female = pd.concat([df1.set_index(\"filename\"), df2.set_index('filename')], axis = 1, join = 'inner').reset_index(drop=False)\n",
    "df_female.to_json(\"./data/output/processed_music.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_female.to_json('./data/output/processed_female.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
